import streamlit as st
from transformers import AutoTokenizer, AutoModelForSequenceClassification
import torch
import torch.nn.functional as F
import pandas as pd
import altair as alt

# 1. é é¢åŸºç¤è¨­å®š
st.set_page_config(
    page_title="AI/Human Detector",
    page_icon="ğŸ•µï¸",
    layout="centered"
)

st.title("ğŸ•µï¸ AI vs Human æ–‡ç« åµæ¸¬å™¨")
st.markdown("""
æœ¬å·¥å…·ä½¿ç”¨ Transformer æ¨¡å‹ä¾†åˆ†ææ–‡æœ¬ç‰¹å¾µã€‚
è«‹åœ¨ä¸‹æ–¹è¼¸å…¥æ–‡ç« æ®µè½ï¼Œç³»çµ±å°‡åˆ¤æ–·å…¶ç”± **äººå·¥æ™ºæ…§ (AI)** ç”Ÿæˆçš„å¯èƒ½æ€§ã€‚
""")

# 2. è¼‰å…¥æ¨¡å‹ (é—œéµï¼šä½¿ç”¨ @st.cache_resource é¿å…é‡è¤‡ä¸‹è¼‰)
# é€™è£¡é¸ç”¨ roberta-base-openai-detectorï¼Œé€™æ˜¯åœ¨ GPT-2 output ä¸Šå¾®èª¿éçš„ç¶“å…¸æ¨¡å‹
MODEL_NAME = "radar-ai/radar-roberta-base"

@st.cache_resource
def load_model():
    # é¡¯ç¤ºè¼‰å…¥ä¸­çš„æç¤º
    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)
    model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME)
    return tokenizer, model

# è™•ç†è¼‰å…¥éç¨‹çš„ UI æç¤º
with st.spinner("æ­£åœ¨å•Ÿå‹• AI åµæ¸¬å¼•æ“ï¼Œåˆæ¬¡è¼‰å…¥éœ€ç´„ 30 ç§’..."):
    try:
        tokenizer, model = load_model()
    except Exception as e:
        st.error(f"æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œè«‹æª¢æŸ¥ç¶²è·¯æˆ–è¨˜æ†¶é«”ç‹€æ…‹ã€‚\néŒ¯èª¤è¨Šæ¯: {e}")
        st.stop()

# 3. ä½¿ç”¨è€…ä»‹é¢
text_input = st.text_area(
    "è¼¸å…¥æ¸¬è©¦æ–‡æœ¬ (å»ºè­°è¼¸å…¥è‹±æ–‡ï¼Œæ•ˆæœæœ€ä½³)ï¼š", 
    height=200, 
    placeholder="Paste your text here to analyze..."
)

analyze_btn = st.button("ğŸš€ é–‹å§‹åµæ¸¬", use_container_width=True)

# 4. åµæ¸¬é‚è¼¯
if analyze_btn and text_input:
    if len(text_input.strip()) < 10:
        st.warning("âš ï¸ æ–‡å­—å¤ªçŸ­ï¼Œè«‹è‡³å°‘è¼¸å…¥ä¸€å€‹å®Œæ•´çš„å¥å­ã€‚")
    else:
        try:
            # å°‡æ–‡å­—è½‰ç‚ºæ¨¡å‹å¯è®€çš„æ ¼å¼
            inputs = tokenizer(text_input, return_tensors="pt", truncation=True, max_length=512)
            
            # é€²è¡Œé æ¸¬
            with torch.no_grad():
                logits = model(**inputs).logits
            
            # è¨ˆç®—æ©Ÿç‡ (Softmax)
            probabilities = F.softmax(logits, dim=1).tolist()[0]
            
            # è©²æ¨¡å‹çš„æ¨™ç±¤å®šç¾©ï¼šIndex 0 = Fake (AI), Index 1 = Real (Human)
            ai_prob = probabilities[0]
            human_prob = probabilities[1]
            
            # 5. é¡¯ç¤ºçµæœ
            st.divider()
            st.subheader("åˆ†æå ±å‘Š")

            # åˆ¤æ–·çµæœæ–‡å­—
            col1, col2 = st.columns(2)
            
            with col1:
                st.metric("ğŸ¤– AI ç”Ÿæˆæ©Ÿç‡", f"{ai_prob:.2%}")
            with col2:
                st.metric("ğŸ§‘ äººé¡æ’°å¯«æ©Ÿç‡", f"{human_prob:.2%}")

            # é€²åº¦æ¢è¦–è¦ºåŒ–
            if ai_prob > human_prob:
                st.error(f"ğŸš¨ çµè«–ï¼šé€™ç¯‡æ–‡ç« å¾ˆé«˜æ©Ÿç‡æ˜¯ **AI ç”Ÿæˆ** çš„ã€‚")
                st.progress(ai_prob, text="AI Probability")
            else:
                st.success(f"âœ… çµè«–ï¼šé€™ç¯‡æ–‡ç« å¾ˆé«˜æ©Ÿç‡æ˜¯ **äººé¡æ’°å¯«** çš„ã€‚")
                st.progress(human_prob, text="Human Probability")

            # åœ–è¡¨è¦–è¦ºåŒ– (åŠ åˆ†é …)
            st.write("---")
            st.caption("æ©Ÿç‡åˆ†ä½ˆåœ–è¡¨ï¼š")
            chart_data = pd.DataFrame({
                "ä¾†æº": ["AI (Fake)", "Human (Real)"],
                "æ©Ÿç‡": [ai_prob, human_prob]
            })
            st.write("---")
            st.caption("æ©Ÿç‡åˆ†ä½ˆåœ–è¡¨ï¼š")
            
            # æº–å‚™è³‡æ–™
            chart_data = pd.DataFrame({
                "Source": ["AI (Fake)", "Human (Real)"],
                "Probability": [ai_prob, human_prob]
            })

            # ä½¿ç”¨ Altair ä¾†ç¹ªè£½ï¼Œé€™æ¨£å¯ä»¥ç²¾æº–æŒ‡å®šé¡è‰²
            c = alt.Chart(chart_data).mark_bar().encode(
                x=alt.X('Source', title='ä¾†æº'),
                y=alt.Y('Probability', title='æ©Ÿç‡'),
                # æŒ‡å®šé¡è‰²ï¼šAI ç”¨ç´…è‰² (#FF4B4B)ï¼ŒHuman ç”¨ç¶ è‰² (#00CC96)
                color=alt.Color('Source', scale=alt.Scale(
                    domain=['AI (Fake)', 'Human (Real)'],
                    range=['#FF4B4B', '#00CC96']
                ), legend=None)
            )

            st.altair_chart(c, use_container_width=True)
            
        except Exception as e:
            st.error(f"åµæ¸¬éç¨‹ä¸­ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")

# é å°¾
st.markdown("---")
st.caption("Model: `roberta-base-openai-detector` | Framework: `Streamlit`")
